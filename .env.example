# Agent Patterns Environment Configuration
# Copy this file to .env and fill in your actual API keys

# =============================================================================
# LLM API Keys
# =============================================================================

# OpenAI API Key (for GPT models)
OPENAI_API_KEY=your-openai-api-key-here

# Anthropic API Key (for Claude models)
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# =============================================================================
# Model Configuration - Thinking Role
# Primary reasoning and planning model (typically most capable/expensive)
# =============================================================================
THINKING_MODEL_PROVIDER=openai
THINKING_MODEL_NAME=gpt-4-turbo
# Alternative: THINKING_MODEL_PROVIDER=anthropic
# Alternative: THINKING_MODEL_NAME=claude-3-5-sonnet-20241022

# =============================================================================
# Model Configuration - Reflection Role
# Self-critique and evaluation model (can be same as thinking or different)
# =============================================================================
REFLECTION_MODEL_PROVIDER=openai
REFLECTION_MODEL_NAME=gpt-4-turbo
# Alternative: REFLECTION_MODEL_PROVIDER=anthropic
# Alternative: REFLECTION_MODEL_NAME=claude-3-5-sonnet-20241022

# =============================================================================
# Model Configuration - Documentation Role
# Output generation and documentation (can use cheaper model)
# =============================================================================
DOCUMENTATION_MODEL_PROVIDER=openai
DOCUMENTATION_MODEL_NAME=gpt-3.5-turbo
# Alternative: DOCUMENTATION_MODEL_PROVIDER=anthropic
# Alternative: DOCUMENTATION_MODEL_NAME=claude-3-haiku-20240307

# =============================================================================
# Model Configuration - Planning Role
# Planning and task decomposition (typically expensive model)
# =============================================================================
PLANNING_MODEL_PROVIDER=openai
PLANNING_MODEL_NAME=gpt-4-turbo

# =============================================================================
# Model Configuration - Execution Role
# Task execution and tool calling (can use cheaper model)
# =============================================================================
EXECUTION_MODEL_PROVIDER=openai
EXECUTION_MODEL_NAME=gpt-3.5-turbo

# =============================================================================
# Optional: Model Parameters
# =============================================================================

# Temperature for different roles (0.0 to 1.0)
THINKING_TEMPERATURE=0.7
REFLECTION_TEMPERATURE=0.5
DOCUMENTATION_TEMPERATURE=0.7
PLANNING_TEMPERATURE=0.5
EXECUTION_TEMPERATURE=0.3

# Max tokens for responses
THINKING_MAX_TOKENS=2000
REFLECTION_MAX_TOKENS=1000
DOCUMENTATION_MAX_TOKENS=2000
PLANNING_MAX_TOKENS=1500
EXECUTION_MAX_TOKENS=1000

# =============================================================================
# Pattern-Specific Configuration
# =============================================================================

# Maximum iterations/trials for looping patterns
MAX_ITERATIONS=5
MAX_TRIALS=3
MAX_REFLECTION_CYCLES=2

# =============================================================================
# Logging and Debugging
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Enable verbose output for debugging
VERBOSE=false

# =============================================================================
# Notes
# =============================================================================
# - Never commit your actual .env file with real API keys
# - Add .env to your .gitignore file
# - Each pattern can override these defaults in their constructor
# - Provider must be one of: openai, anthropic, or other LangChain-supported providers
